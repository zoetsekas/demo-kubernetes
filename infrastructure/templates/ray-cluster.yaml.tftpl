apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: ray-cluster
  namespace: ml-workloads
  labels:
    app: ray-cluster
spec:
  headGroupSpec:
    serviceType: ClusterIP
    rayStartParams:
      dashboard-host: '0.0.0.0'
      metrics-export-port: '8080'
    template:
      spec:
        serviceAccountName: ray-worker-sa
        containers:
        - name: ray-head
          image: ${artifact_registry}/${image_name}:${tag}
          env:
          - name: RAY_GRAFANA_HOST
            value: http://grafana.ml-workloads.svc.cluster.local:3000
          - name: RAY_CLIENT_REBIND_ATTACK_PROTECTION_ENABLED
            value: "0"
          - name: RAY_DASHBOARD_FRONTEND_HOST_CHECK
            value: "false"
          resources:
            limits:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "0" # Head node usually doesn't need GPU unless running tasks
            requests:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "0"
          ports:
          - containerPort: 6379
            name: gcs-server
          - containerPort: 8265 # Dashboard
            name: dashboard
          - containerPort: 10001 # Client
            name: client
          - containerPort: 8000 # Serve
            name: serve
          - containerPort: 8080
            name: metrics
          - containerPort: 8081
            name: as-metrics
          - containerPort: 8082
            name: dash-metrics
  workerGroupSpecs:
  - replicas: 0
    minReplicas: 0
    maxReplicas: 0
    groupName: gpu-group
    rayStartParams: {}
    template:
      spec:
        serviceAccountName: ray-worker-sa
        containers:
        - name: ray-worker
          image: ${artifact_registry}/${image_name}:${tag}
          resources:
            limits:
              cpu: "3"
              memory: "8Gi"
              nvidia.com/gpu: "1"
            requests:
              cpu: "3"
              memory: "8Gi"
              nvidia.com/gpu: "1"
          ports:
          - containerPort: 8080
            name: metrics
        tolerations:
        - key: "nvidia.com/gpu"
          operator: "Equal"
          value: "present"
          effect: "NoSchedule"
  - replicas: 2
    minReplicas: 2
    maxReplicas: 5
    groupName: cpu-group
    rayStartParams: {}
    template:
      spec:
        serviceAccountName: ray-worker-sa
        containers:
        - name: ray-worker
          image: ${artifact_registry}/${image_name}:${tag}
          resources:
            limits:
              cpu: "2"
              memory: "4Gi"
              nvidia.com/gpu: "0"
            requests:
              cpu: "2"
              memory: "4Gi"
              nvidia.com/gpu: "0"
          ports:
          - containerPort: 8080
            name: metrics
