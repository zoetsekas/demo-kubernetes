apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: ray-cluster
  namespace: ml-workloads
  labels:
    app: ray-cluster
spec:
  headGroupSpec:
    serviceType: ClusterIP
    rayStartParams:
      dashboard-host: '0.0.0.0'
      metrics-export-port: '8080'
    template:
      spec:
        serviceAccountName: ray-worker-sa
        containers:
        - name: ray-head
          image: ${artifact_registry}/${image_name}:${tag}
          env:
          - name: RAY_GRAFANA_HOST
            value: http://grafana.ml-workloads.svc.cluster.local:3000
          resources:
            limits:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "0" # Head node usually doesn't need GPU unless running tasks
            requests:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "0"
          ports:
          - containerPort: 6379
            name: gcs-server
          - containerPort: 8265 # Dashboard
            name: dashboard
          - containerPort: 10001 # Client
            name: client
          - containerPort: 8000 # Serve
            name: serve
          - containerPort: 8080
            name: metrics
          - containerPort: 8081
            name: as-metrics
          - containerPort: 8082
            name: dash-metrics
  workerGroupSpecs:
  - replicas: 1
    minReplicas: 1
    maxReplicas: 4
    groupName: gpu-group
    rayStartParams: {}
    template:
      spec:
        serviceAccountName: ray-worker-sa
        containers:
        - name: ray-worker
          image: ${artifact_registry}/${image_name}:${tag}
          resources:
            limits:
              cpu: "4"
              memory: "16Gi"
              nvidia.com/gpu: "1"
            requests:
              cpu: "4"
              memory: "16Gi"
              nvidia.com/gpu: "1"
          ports:
          - containerPort: 8080
            name: metrics
          # Depending on GKE version/driver installation, might need tolerations
        nodeSelector:
            iam.gke.io/gke-metadata-server-enabled: "true"
        tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
